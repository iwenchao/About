# 一、操作系统概述
##  操作系统的概念、特征、功能、提供的服务
### 特性
    1. 并发: 同一时间间隔内支持执行多个任务, 对于一个核则是交替执行；
    2. 共享: 硬件资源或数据资源支持多个进程共享；
    3. 异步: 并发情况下， 一个程序会陆陆续续被执行，完成时间不可预知；
    4. 虚拟: 物理实体转化为逻辑实体，如虚拟内存。
### 基本功能
1. CPU管理：对处理器的管理和调度最终归结为对进程和线程的管理和调度，包括进程控制和管理，线程控制和管理，确定处理器调度策略，设计处理器调度算法，做好处理器分配和回收。
2. 存储管理：存储管理的主要任务是管理内存资源，为多道程序运行提供有力支撑，提高存储空间利用率，具体来说有内存分配与回收，地址转换与存储保护，内存共享与存储扩充等。 
3. 设备管理：设备管理的除妖任务是管理各种外部设备，完成用户提出的I/O请求；加快数据传输速度，发挥设备的并行性，提高设备的利用率；提供设备驱动程序和中断处理请求。
4. 文件管理：文件库案例的主要任务有提供文件逻辑组织方法，提供文件物理组织方法，提供文件存取和使用方法，实现文件目录管理，实现文件共享和安全性控制，实现文件存储空间管理等。

### 体系结构
1. 大内核：将操作系统作为一个整体放在内核当中。
2. 微内核：将操作系统的功能进行详细划分，只有微内核在内核态中存在，其他的在用户态。由于存在用户态和内核态的切换所以会影响系统整体性能。

#### 补充
用户栈： 进程在用户空间时创建的栈，比如函数调用时压栈出栈， 保存了函数互相调用的参数/返回值等；
内核栈： 中断进入内核态时，用内核栈来保存用户态进程的状态信息，返回用户钛再将这些信息出栈；内核栈位置在内核的一块固定区域，保存中断现场，进程调用数据等。


### 运行机制
中断：外中断（强迫中断，包括了人为干预、外部设备请求，时钟中断）；内中断（自愿中断：指令中断，强迫中断：硬件或者软件故障）。

异常：

系统调用概念：一个进程在用户态想使用内核态的功能时，就需要进行系统陷入内核状态，其过程由操作系统完成。

### 常见的linux系统调用
Linux系统调用包括：

进程控制：fork(); wait();阻塞 exit();

进程通信：pipe();管道 shmget(); mmap(); 文件地址映射

文件操作：open(); read(); write();

设备操作：ioctrl(); read(); write();

信息维护：getpid(); alarm(); sleep();

安全：chmod(); 改变文件访问权限 umask(); chown();


那么我们主要围绕这进程管理和内存管理的基本功能来进行整理。

# 二、进程管理
## 进程与线程
进程：资源分配的基本单位，进程控制块（PCB）记录进程的基本信息和运行状态。程序会调用一个或多个进程。

线程：独立调度的基本单位，一个进程中有多个线程占有共有资源。

### 进程的状态和转换
创建-就绪-运行-阻塞-终止。
注意：只有就绪状态和运行状态之间存在回路。就绪状态通过进程调度算法获得CPU时间，转为运行态。而运行状态在CPU时间用完之后会转为就绪状态，等待下一次调度。阻塞状态是缺少资源从而由运行状态到阻塞状态转换而来，不包括CPU时间。特别是没有CPU时间会从运行状态转移到就绪状态。


### 进程控制块
进程控制块是进程存在的唯一标识，是操作系统用来记录和刻画进程状态及环境信息的数据结构，是进程动态特征的汇集，也是操作系统掌握进程的唯一资料结构和管理进程的主
要依据。
（1）标识信息:标识信息用于唯一地标识一个进程，分为用户使用的外部标识符合系统使用的内部标识号。
（2）现场信息：现场信息用于保存进程在运行时存放在处理器现场中的各种信息。
（3）控制信息：控制信息用于管理和调度进程
### 进程通信（共享存储系统、消息传递系统、管道通信）
1. 管道( pipe )：
管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。有名管道(named pipe)也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。
2. 信号量( semophore )：
信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。
3. 消息队列( message queue )：
消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。
4. 信号( signal )：
信号是比较复杂的通信方式，用于通知接受进程有某种事件发生，除了用于进程间通信外，进程还可以发送信号给进程本身；linux除了支持Unix早期信号语义函数sigal外，还支持语义符合Posix.1标准的信号函数sigaction（实际上，该函数是基于BSD的，BSD为了实现可靠信号机制，又能够统一对外接口，用sigaction函数重新实现了signal函数）。
5. 共享内存( shared memory )：
共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号两，配合使用，来实现进程间的同步和通信。
6. 套接字( socket )：套解口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同及其间的进程通信。

### 进程与线程的区别
- 地址空间：进程中线程共享进程的地址空间；而进程有自己的地址空间。
- 资源拥有：进程是资源分配和拥有的单位；而同一进程中的线程共享进程的资源。（各线程有自己的程序计数器、寄存器、堆栈、状态）
- 进程是资源分配的基本单位；线程是处理器调度的基本单位。
- 占有资源：进程是资源分配的基本单位，线程不拥有独立的资源，可访问在独立进程下的资源。
- 调度：线程是调度的基本单位，同一进程之间的线程是不引起进程的切换，进程切换会引起切换。
- 系统开销：进程（资源回收）之间的调度会花费比线程（寄存器信息存储）多的资源空间。
- 通信方面：进程通信需要用到：互斥和同步。线程通信需要创建全局变量。

- 为什么要引入线程？
进程是资源拥有者。在创建、切换和撤销的操作需要较大的时空开销，限制了并发程度的进一步提高。引入线程将进程作为资源分配单位和资源调度单位这两个属性分开处理。进程任作为资源分配的基本单位；把调度执行和切换的任务交给线程。

### 进程调度算法
- 批处理系统：先来先服务（FIFO）、短作业优先、最短剩余时间按优先。
- 交互式处理系统：时间片轮转、队列优先级调度、多级反馈机制。
- 实时系统：硬实时（在规定时间内完成任务，不允许有误差，计算精度高的处理任务）、软实时（在规定时间内可以有延迟，订票）。

### 典型的调度算法（先来先服务、短作业优先、时间片轮转、优先级、高响应比、多级反馈队列调度算法）
- 先来先服务（FCFS , First Come First Served） 特点：适合长作业，不利于段作业；适合CPU繁忙型作业，不利于I/O繁忙型作业。
- 短作业优先（SJF, Shortest Job First） 特点：提高了系统吞吐量；对长作业不利，有可能长时间得不到执行。
- 优先级调度（HPF , Highest Priority First） 特点：进程调度每次将处理机分配给具有最高优先级的就绪进程。最高优先级算法可与不同的CPU方式结合形成“可抢占式”最高优先级算法和“不可抢占式”最高优先级算法。常用于批处理系统。
- 高响应比优先（HRN，Highest Response_ratio Next） 特点：HRN是对FCFS方式和SJF方式的一种综合平衡。 响应比R=(W + T)/ T . 其中W为等待时间，T为需要执行时间。
- 时间片轮转算法（RR，Round Robin） 特点：时间片轮转调度是一种最古老，最简单，最公平且使用最广的算法。将CPU的处理时间划分成一个个的时间片，就绪队列中的进程轮流运行一个时间片。当时间片结束时，就强迫进程让出CPU，该进程进入就绪队列，等待下一次调度，同时，进程调度又去选择就绪队列中的一个进程，分配给它一个时间片，以投入运行。
- 多级队列轮转算法：几种调度算法的结合形式多级队列方式。

### 同步与互斥
#### 进程同步的基本概念
临界资源：一次只允许一个进程使用。
同步和互斥：同步多个进程依次执行，互斥多个进程只有一个进程进入临界区。
信号量：down阻塞，P操作；up唤醒，V操作。

             2、实现临界区互斥的基本方法（软件实现方法、硬件实现方法）

             3、信号量

             4、管程

##### 经典同步问题
- 生产者-消费者问题、
- 读者-写者问题、
- 哲学家进餐问题

#### 死锁
##### 死锁的概念
如果在一个进程集合中的每个进程都在等待只能由该集合中的其它一个进程才能引发的事件，而无限期陷入僵持的局面称为死锁
如：假如双方都拥有部分资源（P1拥有A，P2拥有B，且A，B均只有一个），但这时P1还需要B，P2还需要A，于是P1与P2都会处在无限等待状态，发生了死锁。

补充：饥饿
饥饿是指一个进程由于其它进程总是优先于它而被无限期拖延
考虑一台打印机分配的例子，当有多个进程需要打印文件时，系统按照短文件优先的策略排序，该策略具有平均等待时间短的优点，似乎非常合理，但当短文件打印任务源源不断时，长文件的打印任务将被无限期地推迟，导致饥饿

##### 死锁的条件
互斥、占有和等待、不抢占、环路等待。
##### 死锁预防
破坏互斥、破坏占有和等待、破坏不抢占和破坏环路等待。
##### 死锁避免
安全状态：不发生死锁而且进程要求的进程请求最大。单银行家资源算法，多银行家资源算法。
##### 死锁检测与解除
鸵鸟策略（忽视）；死锁检测和恢复（检测：有向环路检测，满足环路即死锁；每种类型多个资源检测：未被标记发生死锁。恢复：抢占，回滚，杀死进程）


### 线程同步
1. 几种方式
    - 互斥锁：提供对临界资源的保护，当多线程试图访问临界资源时，都必须通过获取锁的方式来访问临界资源。（临界资源：是被多线程共享的资源）
    - 条件变量：提供线程之间的一种通知机制，当某一条件满足时，线程A可以通知阻塞在条件变量上的线程B，B所期望的条件已经满足，可以解除在条件变量上的阻塞操作，继续做其他事情。
    - 信号量：提供对临界资源的安全分配。如果存在多份临界资源，在多个线程争抢临界资源的情况下，向线程提供安全分配临界资源的方法。如果临界资源的数量为1，将退化为锁。

### 内存池，进程池，线程池
池的概念 由于服务器的硬件资源“充裕”，那么提高服务器性能的一个很直接的方法就是以空间换时间，即“浪费”服务器的硬件资源，以换取其运行效率。这就是池的概念。池是一组资源的集合，这组资源在服务器启动之初就完全被创建并初始化，这称为静态资源分配。当服务器进入正是运行阶段，即开始处理客户请求的时候，如果它需要相关的资源，就可以直接从池中获取，无需动态分配。很显然，直接从池中取得所需资源比动态分配资源的速度要快得多，因为分配系统资源的系统调用都是很耗时的。当服务器处理完一个客户连接后，可以把相关的资源放回池中，无需执行系统调用来释放资源。从最终效果来看，池相当于服务器管理系统资源的应用设施，它避免了服务器对内核的频繁访问。 池可以分为多种，常见的有内存池、进程池、线程池和连接池。

二、内存池 c++内存分配优先使用内存池，而不是new，delete。 new和delete首先会转调用到malloc和free，这个大家应该很熟识了。很多人认为malloc是一个很简单的操作，其实巨复杂，它会执行一个系统调用(当然不是每一次，windows上是按页算)，该系统调用会锁住内存硬件，然后通过链表的方式查找空闲内存，如果找到大小合适的，就把用户的进程地址映射到内存硬件地址中，然后释放锁，返回给进程。如果在多线程环境下，进程内的分配也会上锁，跟上面类似，不过不是以页，而是以分配的内存为单位。

内存池就是预先分配好，放到进程空间的内存块，用户申请与释放内存其实都是在进程内进行，SGI-STL的alloc遇到小对象时就是基于内存池的。只有当内存池空间不够时，才会再从系统找一块很大的内存。 所以使用内存池提升了内存分配与回收的效率。

三、进程池与线程池 进程池和线程池相似，所以这里我们以进程池为例进行介绍。如没有特殊声明，下面对进程池的讨论完全是用于线程池。 进程池是由服务器预先创建的一组子进程，这些子进程的数目在3~10个之间（当然这只是典型情况）。线程池中的线程数量应该和CPU数量差不多。进程池中的所有子进程都运行着相同的代码，并具有相同的属性，比如优先级、PGID等。当有新的任务来到时，主进程将通过某种方式选择进程池中的某一个子进程来为之服务（如使用随机算法或轮转法来挑选一个子进程）。当选择好子进程后，主进程还需要使用某种通知机制来告诉目标子进程有新任务需要处理，并传递必要的数据。最简单的方式是，在父进程和子进程之间预先建立好一条管道，然后通过管道来实现所有的进程间通信。在父线程和子线程之间传递数据就要简单得多，因为我们可以把这些数据定义为全局，那么它们本身就是被所有线程共享的。

# 三、内存管理

包括内存管理和虚拟内存管理。

内存管理包括内存管理概念、交换与覆盖、连续分配管理方式和非连续分配管理方式（分页管理方式、分段管理方式、段页式管理方式）。

虚拟内存管理包括虚拟内存概念、请求分页管理方式、页面置换算法、页面分配策略、工作集和抖动。

## 内存管理的基础
虚拟内存的基本思想是每个程序拥有自己的地址空间，这个空间可以被分割成多个块，每个块称为一页，每一页又连续的地址范围。这些页被映射到物理内存，但并不是所有的页都必须在内存中才能运行程序。当程序引用到一部分在物理内存中的地址空间时，由硬件立刻执行必要的映射。当程序引用到不在物理内存中的地址空间时，由操作系统负责将缺失的部分装入物理内存并重新执行失败的命令。
在使用虚拟内存的情况下，虚拟地址会被送到内存管理单元 MMU，MMU 把虚拟地址映射为物理内存地址。
虚拟内存的本质是创造一个新的抽象概念---地址空间，这个概念对应的是物理内存的抽象。虚拟内存的实现是将虚拟地址空间分解成页，并将每一页映射到物理内存的某个页框或者解除映射。
转换检测缓冲区（Translation Lookaside Buffer, TLB）又称为快表，提供中间由虚拟地址转换为物理地址时的缓存，可以直接将虚拟地址映射到物理地址，加速分页过程。
如何处理巨大的虚拟地址空间，
多级页表，分级索引更多的地址空间
倒排页表，使用页框号而不是虚拟页号来索引页表项，中间通过 TLB 加速
          

## 虚拟内存管理
1、虚拟内存基本概念
2、请求分页管理方式
3、页面置换算法（最佳置换算法、先进先出置换算法、最近最少使用置换算法、时钟置换算法）
4、页面分配策略
5、工作集
6、抖动











